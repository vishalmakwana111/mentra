# Long Paragraph Test Cases for Note Similarity (Under 400 Chars)

Use the following paragraphs as content for different notes to test automatic edge creation and score-based labeling/styling, especially focusing on how the system handles longer text within a character limit.

---

## Paragraph 1: Agile Project Management (Shortened)

Agile project management prioritizes iterative development, feedback, and adaptive planning over traditional waterfall methods. It values customer collaboration, working software, individual interactions, and responding to change. Frameworks like Scrum and Kanban use practices like daily stand-ups, sprints, and retrospectives to improve transparency and deliver value quickly, relying on empowered, cross-functional teams.

---

## Paragraph 2: CI/CD Pipelines (Shortened)

**CI/CD pipelines automate software build, test, and deployment using tools like Git, Jenkins/GitLab CI, and testing frameworks. Continuous Integration involves frequent code merging with automated tests to catch errors early. Continuous Deployment automatically deploys validated code to production. This DevOps practice reduces manual effort, minimizes deployment risk, and enables faster delivery of features and fixes.**

---

## Paragraph 3: Microservices Architecture (Shortened)

Microservices structure applications as collections of small, independent, loosely coupled services focused on specific business capabilities, contrasting with monolithic designs. Benefits include independent scaling, fault isolation, technology diversity, and faster development cycles. Challenges involve operational complexity, inter-service communication (APIs, queues), distributed data management, and monitoring.

---

## Paragraph 4: Introduction to Vector Databases (Shortened)

**Vector databases store and query high-dimensional vector embeddings from ML models (representing text, images, etc.). Unlike keyword search, they use Approximate Nearest Neighbor (ANN) algorithms for semantic similarity searches. This powers AI applications like recommendations and anomaly detection. Key factors include index speed, query latency, scalability, and integration. Pinecone and Weaviate are examples.**

---

## Paragraph 5: Retrieval-Augmented Generation (RAG) (Shortened)

**Retrieval-Augmented Generation (RAG) improves LLM answers by grounding them in external knowledge. It retrieves relevant data snippets (e.g., from a vector database) based on the user query, adds this context to the prompt, and instructs the LLM to use it. This reduces hallucinations and allows answers based on information beyond the LLM's training data, enhancing reliability for knowledge tasks.**
